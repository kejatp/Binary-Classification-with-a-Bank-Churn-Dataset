{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5ttisMLk7EW",
        "outputId": "239c0b7c-e4b0-4a50-b6c6-ff7081497bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/81.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.1)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2023.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.4.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.0)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SSPubOwdO_f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, RandomizedSearchCV, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             log_loss, precision_recall_curve, average_precision_score,\n",
        "                             roc_curve, roc_auc_score)\n",
        "from category_encoders import TargetEncoder\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "rXGU7AaldhXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = train['Exited']\n",
        "X_train = train.drop(['Exited', 'id','CustomerId', 'Surname'], axis = 1)\n",
        "test = test.drop([ 'id','CustomerId', 'Surname'], axis = 1)"
      ],
      "metadata": {
        "id": "ctRtSZeidpFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3qWBbX1Bdzpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9G7Mr5oeLri",
        "outputId": "3431fad6-5660-4429-f1ff-5964e895bbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CreditScore        0\n",
              "Geography          0\n",
              "Gender             0\n",
              "Age                0\n",
              "Tenure             0\n",
              "Balance            0\n",
              "NumOfProducts      0\n",
              "HasCrCard          0\n",
              "IsActiveMember     0\n",
              "EstimatedSalary    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBnqftH1en4K",
        "outputId": "b1720e53-78f0-49c9-a686-a60dae4befdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CreditScore        0\n",
              "Geography          0\n",
              "Gender             0\n",
              "Age                0\n",
              "Tenure             0\n",
              "Balance            0\n",
              "NumOfProducts      0\n",
              "HasCrCard          0\n",
              "IsActiveMember     0\n",
              "EstimatedSalary    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etude des données"
      ],
      "metadata": {
        "id": "DbyC7O0Tgzx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "status_counts = train['Exited'].value_counts()"
      ],
      "metadata": {
        "id": "8IEHsguqepVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "status_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDmFaDhIhK3Y",
        "outputId": "954fd6bf-55f6-4546-95bc-9a1b175fe3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    130113\n",
              "1     34921\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot( x = 'Exited', data = train, palette = 'Pastel1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "Ivvc8Ol8hMiz",
        "outputId": "d7c37cd5-a630-4fea-f11b-e2fbd4ad84de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-3f75f79ccb00>:1: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot( x = 'Exited', data = train, palette = 'Pastel1')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Exited', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imbalanced data"
      ],
      "metadata": {
        "id": "jRP51xqhh4uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of numerical value\n",
        "numerical_vars = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i, var in enumerate(numerical_vars, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    plt.hist(train[var], bins=20, color='skyblue', edgecolor='black')\n",
        "    plt.title(f'Distribution of {var}')\n",
        "    plt.xlabel(var)\n",
        "    plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "pxrZZoulhq5N",
        "outputId": "6d1c1e36-c83e-44b5-908f-7b8434f99eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pie chart for categorical variables\n",
        "categ_vals = ['Geography','Gender', 'HasCrCard', 'IsActiveMember']\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i,var in enumerate(categ_vals, 1):\n",
        "  plt.subplot(2,2,i)\n",
        "  counts = train[var].value_counts()\n",
        "  plt.pie(counts, labels = counts.index, autopct='%1.1f%%', startangle = 140, colors = sns.color_palette('Pastel1'))\n",
        "  plt.title(f'{var} Pie chart')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5TMJclu9iBZD",
        "outputId": "5158a236-7813-42dc-e32a-8394c41b0cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#regardons quelles variables sont interessante pour notre étude\n",
        "plt.figure(figsize = (12,8))\n",
        "for i,var in enumerate(numerical_vars, 1):\n",
        "  plt.subplot(2,3,i)\n",
        "  sns.barplot(x = 'Exited', y = var, data = train, palette = 'Pastel1')\n",
        "  plt.title(f'{var} vs Exited')\n",
        "  plt.xlabel('Exited')\n",
        "  plt.ylabel(var)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iEVjbr99jEfV",
        "outputId": "243c7f55-646a-47d1-8120-7f75d279bc93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-9510f0e67d85>:5: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x = 'Exited', y = var, data = train, palette = 'Pastel1')\n",
            "<ipython-input-61-9510f0e67d85>:5: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x = 'Exited', y = var, data = train, palette = 'Pastel1')\n",
            "<ipython-input-61-9510f0e67d85>:5: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x = 'Exited', y = var, data = train, palette = 'Pastel1')\n",
            "<ipython-input-61-9510f0e67d85>:5: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x = 'Exited', y = var, data = train, palette = 'Pastel1')\n",
            "<ipython-input-61-9510f0e67d85>:5: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x = 'Exited', y = var, data = train, palette = 'Pastel1')\n",
            "<ipython-input-61-9510f0e67d85>:5: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x = 'Exited', y = var, data = train, palette = 'Pastel1')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "prepocessing"
      ],
      "metadata": {
        "id": "7P1_A_JLnOSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = train.drop(['Geography','Gender', 'HasCrCard', 'IsActiveMember'] + [\"id\", \"CustomerId\", \"Surname\"] + ['Exited'], axis = 1)\n",
        "cat_cols = train.drop(['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary'] + [\"id\", \"CustomerId\", \"Surname\"] + ['Exited'], axis = 1)"
      ],
      "metadata": {
        "id": "5Q3lYTvml6Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 19"
      ],
      "metadata": {
        "id": "iHtTwf2EplTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spleeting data\n",
        "\n",
        "X_train,X_valid,y_train, y_valid = train_test_split(X_train, Y_train, test_size = 0.20)"
      ],
      "metadata": {
        "id": "lBvpKRWDeC8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scale_pos_weight = train['Exited'].value_counts()[0] / train['Exited'].value_counts()[1]"
      ],
      "metadata": {
        "id": "EjUPtSCarJvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_transformer = Pipeline(steps = [('num_imputer', SimpleImputer(strategy = 'median')), ('scaler', StandardScaler())])\n",
        "cat_transformer = Pipeline(steps = [('cat_imputer', SimpleImputer(strategy = 'most_frequent')), ('encoder', TargetEncoder())])\n",
        "\n",
        "feature_transformations = ColumnTransformer(transformers = [('num_transformations', num_transformer, numerical_vars), ('cat_transformations', cat_transformer, categ_vals)])\n",
        "\n",
        "pipe =Pipeline(steps = [('feature_transformations' , feature_transformations), ('model', LGBMClassifier())])\n",
        "\n",
        "params_grid = [{'feature_transformations' : [feature_transformations],\n",
        "                'model' : [LGBMClassifier(verbosity =  1)],\n",
        "                'model__n_estimators': [int(x) for x in np.linspace(75, 150, num=75)],\n",
        "                'model__max_depth' : [int(x) for x in np.linspace(3, 12, num=9)],\n",
        "                'model__learning_rate' : np.linspace(0.01, 0.5),\n",
        "                'model__class_weight' : [None, 'balanced'],\n",
        "                'model__random_state' : [seed],\n",
        "                'model__importance_type' : ['gain']\n",
        "                },\n",
        "               {'feature_transformations': [feature_transformations],\n",
        "                'model': [XGBClassifier(verbosity=0)],\n",
        "                'model__n_estimators': [int(x) for x in np.linspace(75, 150, num=75)],\n",
        "                'model__max_depth': [int(x) for x in np.linspace(3, 12, num=9)],\n",
        "                'model__learning_rate': np.linspace(0.01, 0.5),\n",
        "                'model__scale_pos_weight': [None, scale_pos_weight],\n",
        "                'model__random_state': [seed],\n",
        "                'model__importance_type': ['gain']}\n",
        "\n",
        "               ]\n",
        "\n"
      ],
      "metadata": {
        "id": "VhpCs1_EijkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_refit_criteria(cv_results_):\n",
        "    cv_results_ = {key.replace(\"test\", \"validation\") if \"test\" in key\n",
        "                   else key: value for key, value in cv_results_.items()}\n",
        "\n",
        "    return np.argmax(cv_results_['mean_validation_roc_auc'] - cv_results_['std_validation_roc_auc'])"
      ],
      "metadata": {
        "id": "4wqVHSwDq4z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_metrics = {'accuracy' : 'accuracy',\n",
        "                      'precision' : 'precision',\n",
        "                      'recall' : 'recall',\n",
        "                      'f1_score' : 'f1',\n",
        "                      'avg_precision' : 'average_precision',\n",
        "                      'roc_auc' : 'roc_auc'}\n",
        "\n",
        "cross_validator = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=seed)\n",
        "\n",
        "best_model_pipe = RandomizedSearchCV(estimator = pipe,\n",
        "                                     param_distributions = params_grid,\n",
        "                                     n_iter = 300,\n",
        "                                     cv = cross_validator,\n",
        "                                     scoring = evaluation_metrics,\n",
        "                                     refit = custom_refit_criteria,\n",
        "                                     error_score = 'raise',\n",
        "                                     return_train_score = False,\n",
        "                                     random_state = seed,\n",
        "                                     verbose = 1)\n",
        "\n",
        "\n",
        "best_model_pipe.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\n-> Best Pipeline found in RandomSearchCV hyperparameter optimizer:\\n {best_model_pipe.best_estimator_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9AIncLCrb3n",
        "outputId": "5fd6f1d0-693b-4a2c-db84-bc312928ca07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003713 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003932 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003737 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003760 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006961 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003740 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003931 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003728 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003797 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005389 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006738 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003968 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003858 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003802 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003736 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003942 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004061 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003887 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003731 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013341 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004060 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003863 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003856 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003764 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003816 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003835 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003825 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003730 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006697 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003919 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003775 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003949 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006710 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003760 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004007 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003853 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003769 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003934 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003925 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004032 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003891 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003857 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003944 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006361 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003984 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003814 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003776 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003779 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003838 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003939 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003968 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006762 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006676 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003870 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003727 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003956 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003743 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003761 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003812 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003990 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003935 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003968 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006797 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003822 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003726 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003835 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004287 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022599 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003974 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003932 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003891 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003904 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007747 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003764 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003871 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003849 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006758 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003804 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003793 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003962 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003935 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007042 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003867 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003726 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003888 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022847 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003730 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003816 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003746 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003964 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006526 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003930 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003845 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003724 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003898 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004591 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003925 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003788 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003832 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003836 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003855 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007264 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003786 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003794 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003938 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003889 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003926 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006747 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003731 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006710 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003841 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003741 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003798 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003747 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006795 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003822 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003913 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003767 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006441 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003815 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003844 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003874 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007389 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003995 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003873 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003916 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011389 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003929 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003765 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003913 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006720 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003952 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003881 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006899 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003873 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003941 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003908 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003917 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003716 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003888 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003811 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003940 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003781 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003866 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003812 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003712 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006463 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003759 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003974 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003773 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003870 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007338 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003768 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003848 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003912 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003890 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003849 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003868 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004001 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003904 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003784 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003745 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006517 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003829 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003801 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003840 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003803 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003833 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004219 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003848 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006457 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004723 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003729 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003912 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003928 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020212 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003828 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004044 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003817 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003913 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003812 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003827 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009442 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003736 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003806 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003843 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003841 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004467 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003910 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003942 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003831 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006437 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003908 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003933 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003797 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003776 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003796 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003880 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009215 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003934 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003880 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003761 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007345 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003807 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003811 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003768 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003808 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210943 -> initscore=-1.319251\n",
            "[LightGBM] [Info] Start training from score -1.319251\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006769 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003908 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003772 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003723 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 22280, number of negative: 83341\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003830 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 862\n",
            "[LightGBM] [Info] Number of data points in the train set: 105621, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "\n",
            "-> Best Pipeline found in RandomSearchCV hyperparameter optimizer:\n",
            " Pipeline(steps=[('feature_transformations',\n",
            "                 ColumnTransformer(transformers=[('num_transformations',\n",
            "                                                  Pipeline(steps=[('num_imputer',\n",
            "                                                                   SimpleImputer(strategy='median')),\n",
            "                                                                  ('scaler',\n",
            "                                                                   StandardScaler())]),\n",
            "                                                  ['CreditScore', 'Age',\n",
            "                                                   'Tenure', 'Balance',\n",
            "                                                   'NumOfProducts',\n",
            "                                                   'EstimatedSalary']),\n",
            "                                                 ('cat_transformations',\n",
            "                                                  Pipeline(steps=[('cat_imputer',\n",
            "                                                                   SimpleImputer(strategy='mos...\n",
            "                               feature_types=None, gamma=None, grow_policy=None,\n",
            "                               importance_type='gain',\n",
            "                               interaction_constraints=None, learning_rate=0.19,\n",
            "                               max_bin=None, max_cat_threshold=None,\n",
            "                               max_cat_to_onehot=None, max_delta_step=None,\n",
            "                               max_depth=5, max_leaves=None,\n",
            "                               min_child_weight=None, missing=nan,\n",
            "                               monotone_constraints=None, multi_strategy=None,\n",
            "                               n_estimators=79, n_jobs=None,\n",
            "                               num_parallel_tree=None, random_state=19, ...))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_pipe.cv_results_ = {key.replace(\"test\", \"validation\") if \"test\" in key\n",
        "                               else key: value for key, value in best_model_pipe.cv_results_.items()}\n",
        "\n",
        "# Visualizing all results and metrics, from all models, obtained by the RandomSearchCV steps\n",
        "df_results = pd.DataFrame(best_model_pipe.cv_results_)\n",
        "\n",
        "display(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "VzPyWXj9RRFY",
        "outputId": "e210e1f3-e465-4c7a-fc62-ebfdc07fa678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0         1.740169      0.626774         0.219912        0.007244   \n",
              "1         2.801828      0.429545         0.455997        0.125550   \n",
              "2         2.362106      0.910521         0.455749        0.059124   \n",
              "3         1.911260      0.215566         0.504219        0.065514   \n",
              "4         2.638687      0.673381         0.360383        0.009110   \n",
              "..             ...           ...              ...             ...   \n",
              "295       2.075633      0.517378         0.249577        0.046140   \n",
              "296       2.098003      0.146785         0.522076        0.067179   \n",
              "297       2.367370      0.201705         0.716703        0.086247   \n",
              "298       1.868147      0.248142         0.417362        0.010411   \n",
              "299       1.965168      0.306976         0.447232        0.017533   \n",
              "\n",
              "    param_model__scale_pos_weight param_model__random_state  \\\n",
              "0                        3.725924                        19   \n",
              "1                            None                        19   \n",
              "2                             NaN                        19   \n",
              "3                             NaN                        19   \n",
              "4                        3.725924                        19   \n",
              "..                            ...                       ...   \n",
              "295                          None                        19   \n",
              "296                           NaN                        19   \n",
              "297                           NaN                        19   \n",
              "298                           NaN                        19   \n",
              "299                           NaN                        19   \n",
              "\n",
              "    param_model__n_estimators param_model__max_depth  \\\n",
              "0                          88                      5   \n",
              "1                         116                     10   \n",
              "2                         145                      3   \n",
              "3                         113                      5   \n",
              "4                         144                      8   \n",
              "..                        ...                    ...   \n",
              "295                       112                      4   \n",
              "296                       131                      4   \n",
              "297                       135                      6   \n",
              "298                        98                     12   \n",
              "299                       108                     12   \n",
              "\n",
              "    param_model__learning_rate param_model__importance_type  ...  \\\n",
              "0                         0.12                         gain  ...   \n",
              "1                         0.24                         gain  ...   \n",
              "2                         0.09                         gain  ...   \n",
              "3                         0.27                         gain  ...   \n",
              "4                         0.32                         gain  ...   \n",
              "..                         ...                          ...  ...   \n",
              "295                       0.14                         gain  ...   \n",
              "296                        0.3                         gain  ...   \n",
              "297                        0.1                         gain  ...   \n",
              "298                       0.36                         gain  ...   \n",
              "299                       0.27                         gain  ...   \n",
              "\n",
              "    std_validation_avg_precision rank_validation_avg_precision  \\\n",
              "0                       0.003408                            32   \n",
              "1                       0.002699                           271   \n",
              "2                       0.003346                            82   \n",
              "3                       0.002382                            87   \n",
              "4                       0.001210                           276   \n",
              "..                           ...                           ...   \n",
              "295                     0.003297                            10   \n",
              "296                     0.003341                            88   \n",
              "297                     0.002952                            26   \n",
              "298                     0.003475                           197   \n",
              "299                     0.002815                           164   \n",
              "\n",
              "    split0_validation_roc_auc split1_validation_roc_auc  \\\n",
              "0                    0.886142                  0.887698   \n",
              "1                    0.873207                  0.873240   \n",
              "2                    0.885290                  0.887069   \n",
              "3                    0.884818                  0.886787   \n",
              "4                    0.870447                  0.868764   \n",
              "..                        ...                       ...   \n",
              "295                  0.886196                  0.887942   \n",
              "296                  0.885289                  0.886832   \n",
              "297                  0.885692                  0.887892   \n",
              "298                  0.881627                  0.884570   \n",
              "299                  0.883529                  0.885225   \n",
              "\n",
              "     split2_validation_roc_auc  split3_validation_roc_auc  \\\n",
              "0                     0.889740                   0.888318   \n",
              "1                     0.873685                   0.875487   \n",
              "2                     0.889724                   0.887778   \n",
              "3                     0.888462                   0.887828   \n",
              "4                     0.870709                   0.870812   \n",
              "..                         ...                        ...   \n",
              "295                   0.890074                   0.888405   \n",
              "296                   0.889487                   0.887858   \n",
              "297                   0.889759                   0.888632   \n",
              "298                   0.884490                   0.883970   \n",
              "299                   0.886703                   0.885273   \n",
              "\n",
              "     split4_validation_roc_auc  mean_validation_roc_auc  \\\n",
              "0                     0.887722                 0.887924   \n",
              "1                     0.871874                 0.873499   \n",
              "2                     0.887182                 0.887408   \n",
              "3                     0.886916                 0.886962   \n",
              "4                     0.867500                 0.869646   \n",
              "..                         ...                      ...   \n",
              "295                   0.887687                 0.888061   \n",
              "296                   0.886160                 0.887125   \n",
              "297                   0.887384                 0.887872   \n",
              "298                   0.882930                 0.883517   \n",
              "299                   0.884739                 0.885094   \n",
              "\n",
              "     std_validation_roc_auc  rank_validation_roc_auc  \n",
              "0                  0.001159                       30  \n",
              "1                  0.001165                      271  \n",
              "2                  0.001425                       72  \n",
              "3                  0.001235                       96  \n",
              "4                  0.001305                      277  \n",
              "..                      ...                      ...  \n",
              "295                0.001249                        8  \n",
              "296                0.001449                       88  \n",
              "297                0.001351                       37  \n",
              "298                0.001111                      193  \n",
              "299                0.001021                      156  \n",
              "\n",
              "[300 rows x 62 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-130bff26-eadc-4ce8-9ebf-29e04af1361c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_model__scale_pos_weight</th>\n",
              "      <th>param_model__random_state</th>\n",
              "      <th>param_model__n_estimators</th>\n",
              "      <th>param_model__max_depth</th>\n",
              "      <th>param_model__learning_rate</th>\n",
              "      <th>param_model__importance_type</th>\n",
              "      <th>...</th>\n",
              "      <th>std_validation_avg_precision</th>\n",
              "      <th>rank_validation_avg_precision</th>\n",
              "      <th>split0_validation_roc_auc</th>\n",
              "      <th>split1_validation_roc_auc</th>\n",
              "      <th>split2_validation_roc_auc</th>\n",
              "      <th>split3_validation_roc_auc</th>\n",
              "      <th>split4_validation_roc_auc</th>\n",
              "      <th>mean_validation_roc_auc</th>\n",
              "      <th>std_validation_roc_auc</th>\n",
              "      <th>rank_validation_roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.740169</td>\n",
              "      <td>0.626774</td>\n",
              "      <td>0.219912</td>\n",
              "      <td>0.007244</td>\n",
              "      <td>3.725924</td>\n",
              "      <td>19</td>\n",
              "      <td>88</td>\n",
              "      <td>5</td>\n",
              "      <td>0.12</td>\n",
              "      <td>gain</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003408</td>\n",
              "      <td>32</td>\n",
              "      <td>0.886142</td>\n",
              "      <td>0.887698</td>\n",
              "      <td>0.889740</td>\n",
              "      <td>0.888318</td>\n",
              "      <td>0.887722</td>\n",
              "      <td>0.887924</td>\n",
              "      <td>0.001159</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.801828</td>\n",
              "      <td>0.429545</td>\n",
              "      <td>0.455997</td>\n",
              "      <td>0.125550</td>\n",
              "      <td>None</td>\n",
              "      <td>19</td>\n",
              "      <td>116</td>\n",
              "      <td>10</td>\n",
              "      <td>0.24</td>\n",
              "      <td>gain</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002699</td>\n",
              "      <td>271</td>\n",
              "      <td>0.873207</td>\n",
              "      <td>0.873240</td>\n",
              "      <td>0.873685</td>\n",
              "      <td>0.875487</td>\n",
              "      <td>0.871874</td>\n",
              "      <td>0.873499</td>\n",
              "      <td>0.001165</td>\n",
              "      <td>271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.362106</td>\n",
              "      <td>0.910521</td>\n",
              "      <td>0.455749</td>\n",
              "      <td>0.059124</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19</td>\n",
              "      <td>145</td>\n",
              "      <td>3</td>\n",
              "      <td>0.09</td>\n",
              "      <td>gain</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003346</td>\n",
              "      <td>82</td>\n",
              "      <td>0.885290</td>\n",
              "      <td>0.887069</td>\n",
              "      <td>0.889724</td>\n",
              "      <td>0.887778</td>\n",
              "      <td>0.887182</td>\n",
              "      <td>0.887408</td>\n",
              "      <td>0.001425</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.911260</td>\n",
              "      <td>0.215566</td>\n",
              "      <td>0.504219</td>\n",
              "      <td>0.065514</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19</td>\n",
              "      <td>113</td>\n",
              "      <td>5</td>\n",
              "      <td>0.27</td>\n",
              "      <td>gain</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002382</td>\n",
              "      <td>87</td>\n",
              "      <td>0.884818</td>\n",
              "      <td>0.886787</td>\n",
              "      <td>0.888462</td>\n",
              "      <td>0.887828</td>\n",
              "      <td>0.886916</td>\n",
              "      <td>0.886962</td>\n",
              "      <td>0.001235</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.638687</td>\n",
              "      <td>0.673381</td>\n",
              "      <td>0.360383</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>3.725924</td>\n",
              "      <td>19</td>\n",
              "      <td>144</td>\n",
              "      <td>8</td>\n",
              "      <td>0.32</td>\n",
              "      <td>gain</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001210</td>\n",
              "      <td>276</td>\n",
              "      <td>0.870447</td>\n",
              "      <td>0.868764</td>\n",
              "      <td>0.870709</td>\n",
              "      <td>0.870812</td>\n",
              "      <td>0.867500</td>\n",
              "      <td>0.869646</td>\n",
              "      <td>0.001305</td>\n",
              "      <td>277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>2.075633</td>\n",
              "      <td>0.517378</td>\n",
              "      <td>0.249577</td>\n",
              "      <td>0.046140</td>\n",
              "      <td>None</td>\n",
              "      <td>19</td>\n",
              "      <td>112</td>\n",
              "      <td>4</td>\n",
              "      <td>0.14</td>\n",
              "      <td>gain</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003297</td>\n",
              "      <td>10</td>\n",
              "      <td>0.886196</td>\n",
              "      <td>0.887942</td>\n",
              "      <td>0.890074</td>\n",
              "      <td>0.888405</td>\n",
              "      <td>0.887687</td>\n",
              "      <td>0.888061</td>\n",
              "      <td>0.001249</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>2.098003</td>\n",
              "      <td>0.146785</td>\n",
              "      <td>0.522076</td>\n",
              "      <td>0.067179</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19</td>\n",
              "      <td>131</td>\n",
              "      <td>4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>gain</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003341</td>\n",
              "      <td>88</td>\n",
              "      <td>0.885289</td>\n",
              "      <td>0.886832</td>\n",
              "      <td>0.889487</td>\n",
              "      <td>0.887858</td>\n",
              "      <td>0.886160</td>\n",
              "      <td>0.887125</td>\n",
              "      <td>0.001449</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>2.367370</td>\n",
              "      <td>0.201705</td>\n",
              "      <td>0.716703</td>\n",
              "      <td>0.086247</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19</td>\n",
              "      <td>135</td>\n",
              "      <td>6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>gain</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002952</td>\n",
              "      <td>26</td>\n",
              "      <td>0.885692</td>\n",
              "      <td>0.887892</td>\n",
              "      <td>0.889759</td>\n",
              "      <td>0.888632</td>\n",
              "      <td>0.887384</td>\n",
              "      <td>0.887872</td>\n",
              "      <td>0.001351</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>1.868147</td>\n",
              "      <td>0.248142</td>\n",
              "      <td>0.417362</td>\n",
              "      <td>0.010411</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19</td>\n",
              "      <td>98</td>\n",
              "      <td>12</td>\n",
              "      <td>0.36</td>\n",
              "      <td>gain</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003475</td>\n",
              "      <td>197</td>\n",
              "      <td>0.881627</td>\n",
              "      <td>0.884570</td>\n",
              "      <td>0.884490</td>\n",
              "      <td>0.883970</td>\n",
              "      <td>0.882930</td>\n",
              "      <td>0.883517</td>\n",
              "      <td>0.001111</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>1.965168</td>\n",
              "      <td>0.306976</td>\n",
              "      <td>0.447232</td>\n",
              "      <td>0.017533</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19</td>\n",
              "      <td>108</td>\n",
              "      <td>12</td>\n",
              "      <td>0.27</td>\n",
              "      <td>gain</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002815</td>\n",
              "      <td>164</td>\n",
              "      <td>0.883529</td>\n",
              "      <td>0.885225</td>\n",
              "      <td>0.886703</td>\n",
              "      <td>0.885273</td>\n",
              "      <td>0.884739</td>\n",
              "      <td>0.885094</td>\n",
              "      <td>0.001021</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 62 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-130bff26-eadc-4ce8-9ebf-29e04af1361c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-130bff26-eadc-4ce8-9ebf-29e04af1361c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-130bff26-eadc-4ce8-9ebf-29e04af1361c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-155839a9-4000-4372-88ab-ed65b65d5d52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-155839a9-4000-4372-88ab-ed65b65d5d52')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-155839a9-4000-4372-88ab-ed65b65d5d52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_results[df_results.index == best_model_pipe.best_index_]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "BEDI5lMNuMtv",
        "outputId": "abfe5fd8-cff0-46a3-c953-0a8f92b510d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "223       1.405338      0.097345         0.261323        0.082836   \n",
              "\n",
              "    param_model__scale_pos_weight param_model__random_state  \\\n",
              "223                          None                        19   \n",
              "\n",
              "    param_model__n_estimators param_model__max_depth  \\\n",
              "223                        79                      5   \n",
              "\n",
              "    param_model__learning_rate param_model__importance_type  ...  \\\n",
              "223                       0.19                         gain  ...   \n",
              "\n",
              "    std_validation_avg_precision rank_validation_avg_precision  \\\n",
              "223                     0.003178                             7   \n",
              "\n",
              "    split0_validation_roc_auc split1_validation_roc_auc  \\\n",
              "223                  0.886343                  0.887777   \n",
              "\n",
              "     split2_validation_roc_auc  split3_validation_roc_auc  \\\n",
              "223                   0.889542                   0.888583   \n",
              "\n",
              "     split4_validation_roc_auc  mean_validation_roc_auc  \\\n",
              "223                   0.887597                 0.887968   \n",
              "\n",
              "     std_validation_roc_auc  rank_validation_roc_auc  \n",
              "223                0.001065                       21  \n",
              "\n",
              "[1 rows x 62 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d55be58-0b22-419b-b7ff-b9d23d10d1de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_model__scale_pos_weight</th>\n",
              "      <th>param_model__random_state</th>\n",
              "      <th>param_model__n_estimators</th>\n",
              "      <th>param_model__max_depth</th>\n",
              "      <th>param_model__learning_rate</th>\n",
              "      <th>param_model__importance_type</th>\n",
              "      <th>...</th>\n",
              "      <th>std_validation_avg_precision</th>\n",
              "      <th>rank_validation_avg_precision</th>\n",
              "      <th>split0_validation_roc_auc</th>\n",
              "      <th>split1_validation_roc_auc</th>\n",
              "      <th>split2_validation_roc_auc</th>\n",
              "      <th>split3_validation_roc_auc</th>\n",
              "      <th>split4_validation_roc_auc</th>\n",
              "      <th>mean_validation_roc_auc</th>\n",
              "      <th>std_validation_roc_auc</th>\n",
              "      <th>rank_validation_roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>1.405338</td>\n",
              "      <td>0.097345</td>\n",
              "      <td>0.261323</td>\n",
              "      <td>0.082836</td>\n",
              "      <td>None</td>\n",
              "      <td>19</td>\n",
              "      <td>79</td>\n",
              "      <td>5</td>\n",
              "      <td>0.19</td>\n",
              "      <td>gain</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003178</td>\n",
              "      <td>7</td>\n",
              "      <td>0.886343</td>\n",
              "      <td>0.887777</td>\n",
              "      <td>0.889542</td>\n",
              "      <td>0.888583</td>\n",
              "      <td>0.887597</td>\n",
              "      <td>0.887968</td>\n",
              "      <td>0.001065</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 62 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d55be58-0b22-419b-b7ff-b9d23d10d1de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d55be58-0b22-419b-b7ff-b9d23d10d1de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d55be58-0b22-419b-b7ff-b9d23d10d1de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_results[df_results.index == best_model_pipe.best_index_][['mean_validation_roc_auc',\n",
        "                                                             'std_validation_roc_auc']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "14QQPwWbRTvi",
        "outputId": "69c4e939-a783-4533-9774-3c79479668f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean_validation_roc_auc  std_validation_roc_auc\n",
              "223                 0.887968                0.001065"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f00d255-bd34-4af8-8d93-79c08a4a8bfa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_validation_roc_auc</th>\n",
              "      <th>std_validation_roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>0.887968</td>\n",
              "      <td>0.001065</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f00d255-bd34-4af8-8d93-79c08a4a8bfa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f00d255-bd34-4af8-8d93-79c08a4a8bfa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f00d255-bd34-4af8-8d93-79c08a4a8bfa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"                                                             'std_validation_roc_auc']]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"mean_validation_roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8879682882099171,\n        \"max\": 0.8879682882099171,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8879682882099171\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_validation_roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0010649372865614156,\n        \"max\": 0.0010649372865614156,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0010649372865614156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_results[df_results.index == best_model_pipe.best_index_][['mean_validation_precision',\n",
        "                                                             'std_validation_precision']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "APLklOeXRapA",
        "outputId": "89b0f520-035e-481c-9e37-45230fbd3e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean_validation_precision  std_validation_precision\n",
              "223                   0.738619                  0.003835"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b143bcf-0aa3-4be0-8110-2ab2a79bdf1d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_validation_precision</th>\n",
              "      <th>std_validation_precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>0.738619</td>\n",
              "      <td>0.003835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b143bcf-0aa3-4be0-8110-2ab2a79bdf1d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b143bcf-0aa3-4be0-8110-2ab2a79bdf1d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b143bcf-0aa3-4be0-8110-2ab2a79bdf1d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"                                                             'std_validation_precision']]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"mean_validation_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7386188902725721,\n        \"max\": 0.7386188902725721,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7386188902725721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_validation_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0038352469771024975,\n        \"max\": 0.0038352469771024975,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0038352469771024975\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = best_model_pipe.predict(X_valid)\n",
        "test_predicted_probabilities = best_model_pipe.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "test_metrics_dict = {'test_accuracy': accuracy_score(y_valid, test_predictions),\n",
        "                     'test_precision': precision_score(y_valid, test_predictions),\n",
        "                     'test_recall': recall_score(y_valid, test_predictions),\n",
        "                     'test_f1_score': f1_score(y_valid, test_predictions),\n",
        "                     'test_avg_precision': average_precision_score(y_valid, test_predicted_probabilities),\n",
        "                     'test_roc_auc': roc_auc_score(y_valid, test_predicted_probabilities)}\n",
        "\n",
        "print(f\"-> Best model's evaluation metrics, hold-out test set:\\n {test_metrics_dict}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bagyqAQtRq_B",
        "outputId": "27b90cbe-2188-4e10-922e-ac374302ca39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Best model's evaluation metrics, hold-out test set:\n",
            " {'test_accuracy': 0.862695791801739, 'test_precision': 0.7334068762640191, 'test_recall': 0.5641352001131382, 'test_f1_score': 0.6377298161470822, 'test_avg_precision': 0.7288245664769666, 'test_roc_auc': 0.8872428223393097}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = pd.read_csv(\"test.csv\")\n",
        "\n",
        "df_submission['Exited'] = best_model_pipe.predict_proba(df_submission.drop([\"id\", \"CustomerId\", \"Surname\"] , axis=1))[:, 1]\n",
        "\n",
        "df_submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ssgzgSDiRu8r",
        "outputId": "aca423a9-2e2b-4dc9-b8e7-20f285c8f1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id  CustomerId    Surname  CreditScore Geography  Gender   Age  \\\n",
              "0       165034    15773898   Lucchese          586    France  Female  23.0   \n",
              "1       165035    15782418       Nott          683    France  Female  46.0   \n",
              "2       165036    15807120         K?          656    France  Female  34.0   \n",
              "3       165037    15808905  O'Donnell          681    France    Male  36.0   \n",
              "4       165038    15607314    Higgins          752   Germany    Male  38.0   \n",
              "...        ...         ...        ...          ...       ...     ...   ...   \n",
              "110018  275052    15662091      P'eng          570     Spain    Male  29.0   \n",
              "110019  275053    15774133        Cox          575    France  Female  36.0   \n",
              "110020  275054    15728456      Ch'iu          712    France    Male  31.0   \n",
              "110021  275055    15687541   Yegorova          709    France  Female  32.0   \n",
              "110022  275056    15663942       Tuan          621    France  Female  37.0   \n",
              "\n",
              "        Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0            2       0.00              2        0.0             1.0   \n",
              "1            2       0.00              1        1.0             0.0   \n",
              "2            7       0.00              2        1.0             0.0   \n",
              "3            8       0.00              1        1.0             0.0   \n",
              "4           10  121263.62              1        1.0             0.0   \n",
              "...        ...        ...            ...        ...             ...   \n",
              "110018       7  116099.82              1        1.0             1.0   \n",
              "110019       4  178032.53              1        1.0             1.0   \n",
              "110020       2       0.00              2        1.0             0.0   \n",
              "110021       3       0.00              1        1.0             1.0   \n",
              "110022       7   87848.39              1        1.0             0.0   \n",
              "\n",
              "        EstimatedSalary    Exited  \n",
              "0             160976.75  0.027224  \n",
              "1              72549.27  0.810951  \n",
              "2             138882.09  0.025989  \n",
              "3             113931.57  0.218932  \n",
              "4             139431.00  0.330606  \n",
              "...                 ...       ...  \n",
              "110018        148087.62  0.040416  \n",
              "110019         42181.68  0.117805  \n",
              "110020         16287.38  0.019389  \n",
              "110021        158816.58  0.150190  \n",
              "110022         24210.56  0.167155  \n",
              "\n",
              "[110023 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7526abc9-5710-4b57-9a7c-251a7eedb828\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>165034</td>\n",
              "      <td>15773898</td>\n",
              "      <td>Lucchese</td>\n",
              "      <td>586</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>160976.75</td>\n",
              "      <td>0.027224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>165035</td>\n",
              "      <td>15782418</td>\n",
              "      <td>Nott</td>\n",
              "      <td>683</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>46.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72549.27</td>\n",
              "      <td>0.810951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>165036</td>\n",
              "      <td>15807120</td>\n",
              "      <td>K?</td>\n",
              "      <td>656</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>34.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>138882.09</td>\n",
              "      <td>0.025989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>165037</td>\n",
              "      <td>15808905</td>\n",
              "      <td>O'Donnell</td>\n",
              "      <td>681</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>36.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>0.218932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>165038</td>\n",
              "      <td>15607314</td>\n",
              "      <td>Higgins</td>\n",
              "      <td>752</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>38.0</td>\n",
              "      <td>10</td>\n",
              "      <td>121263.62</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>139431.00</td>\n",
              "      <td>0.330606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110018</th>\n",
              "      <td>275052</td>\n",
              "      <td>15662091</td>\n",
              "      <td>P'eng</td>\n",
              "      <td>570</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>29.0</td>\n",
              "      <td>7</td>\n",
              "      <td>116099.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>148087.62</td>\n",
              "      <td>0.040416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110019</th>\n",
              "      <td>275053</td>\n",
              "      <td>15774133</td>\n",
              "      <td>Cox</td>\n",
              "      <td>575</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36.0</td>\n",
              "      <td>4</td>\n",
              "      <td>178032.53</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>42181.68</td>\n",
              "      <td>0.117805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110020</th>\n",
              "      <td>275054</td>\n",
              "      <td>15728456</td>\n",
              "      <td>Ch'iu</td>\n",
              "      <td>712</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16287.38</td>\n",
              "      <td>0.019389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110021</th>\n",
              "      <td>275055</td>\n",
              "      <td>15687541</td>\n",
              "      <td>Yegorova</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>158816.58</td>\n",
              "      <td>0.150190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110022</th>\n",
              "      <td>275056</td>\n",
              "      <td>15663942</td>\n",
              "      <td>Tuan</td>\n",
              "      <td>621</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>37.0</td>\n",
              "      <td>7</td>\n",
              "      <td>87848.39</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24210.56</td>\n",
              "      <td>0.167155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>110023 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7526abc9-5710-4b57-9a7c-251a7eedb828')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7526abc9-5710-4b57-9a7c-251a7eedb828 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7526abc9-5710-4b57-9a7c-251a7eedb828');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b64b75d-afe9-4309-880e-e6922eea5da7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b64b75d-afe9-4309-880e-e6922eea5da7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b64b75d-afe9-4309-880e-e6922eea5da7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_submission"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission[['id', 'Exited']].to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "OzocZUcySusv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vY9V_vANSesZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}